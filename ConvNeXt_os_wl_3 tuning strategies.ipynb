{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869cb51b-1edf-4a19-8cf0-e049557fb5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 4090 D\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import ConvNextForImageClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4645ae48-ca4d-4c41-804d-cd1a989e8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "LABEL_MAP = {\"bonafide\": 1, \"spoof\": 0}\n",
    "\n",
    "class ConvNextFlacDataset(Dataset):\n",
    "    def __init__(self, csv_path, audio_dir, nrows=None):\n",
    "        self.df = pd.read_csv(csv_path, sep=\" \", header=None, nrows=nrows)\n",
    "        self.audio_dir = audio_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        audio_filename = row[1] + \".flac\"\n",
    "        label_str = row[4]\n",
    "        label = LABEL_MAP[label_str]\n",
    "\n",
    "        flac_path = os.path.join(self.audio_dir, audio_filename)\n",
    "        waveform, sr = torchaudio.load(flac_path)\n",
    "\n",
    "        # Convert to mono\n",
    "        waveform = waveform.mean(dim=0)\n",
    "\n",
    "        # Resample to 16kHz if needed\n",
    "        target_sr = 16000\n",
    "        if sr != target_sr:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # Convert to numpy for librosa\n",
    "        waveform_np = waveform.numpy()\n",
    "\n",
    "        # Compute spectrogram\n",
    "        spec = librosa.stft(waveform_np, n_fft=512, hop_length=160, win_length=400)\n",
    "        mag, _ = librosa.magphase(spec)\n",
    "        spec_db = librosa.amplitude_to_db(mag, ref=np.max)\n",
    "\n",
    "        # Normalize to 0-255 and convert to uint8\n",
    "        spec_norm = (spec_db - spec_db.min()) / (spec_db.max() - spec_db.min() + 1e-9) * 255.0\n",
    "        spec_uint8 = spec_norm.astype(np.uint8)  # shape: [freq, time]\n",
    "\n",
    "        # Truncate or pad to 224x224\n",
    "        H, W = spec_uint8.shape\n",
    "        target_H = min(224, H)\n",
    "        target_W = min(224, W)\n",
    "        start_H = (H - target_H) // 2\n",
    "        start_W = (W - target_W) // 2\n",
    "        spec_cropped = spec_uint8[start_H:start_H + target_H, start_W:start_W + target_W]\n",
    "\n",
    "        # Pad if smaller\n",
    "        padded_img = np.zeros((224, 224), dtype=np.uint8)\n",
    "        padded_img[:target_H, :target_W] = spec_cropped\n",
    "\n",
    "        # Convert to RGB and resize to [3, 224, 224]\n",
    "        img = Image.fromarray(padded_img).convert(\"RGB\")\n",
    "        img_np = np.asarray(img).transpose(2, 0, 1) / 255.0  # [3, 224, 224]\n",
    "\n",
    "        # Normalize using ImageNet stats\n",
    "        mean = np.array([0.485, 0.456, 0.406])[:, None, None]\n",
    "        std = np.array([0.229, 0.224, 0.225])[:, None, None]\n",
    "        img_np = (img_np - mean) / std\n",
    "\n",
    "        return {\n",
    "            \"input_values\": torch.tensor(img_np, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def simple_collate_fn(batch):\n",
    "    specs = [x[\"input_values\"] for x in batch]\n",
    "    labels = [x[\"labels\"] for x in batch]\n",
    "    return {\n",
    "        \"input_values\": torch.stack(specs),\n",
    "        \"labels\": torch.stack(labels)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7cb7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance class techniques: \n",
    "# Oversampling\n",
    "\n",
    "count_0 = 22800\n",
    "count_1 = 2580\n",
    "total = count_0 + count_1\n",
    "\n",
    "# Inverse frequency\n",
    "class_weights = {\n",
    "    0: total / count_0, \n",
    "    1: total / count_1   \n",
    "}\n",
    "\n",
    "# Get all labels from the dataset\n",
    "labels = train_dataset.get_labels()\n",
    "\n",
    "# Assign sample weights\n",
    "sample_weights = [class_weights[label] for label in labels]\n",
    "\n",
    "\n",
    "# Create the sampler\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=45600,\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# Create the DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    sampler=sampler,\n",
    "    collate_fn=simple_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c53c1ba-7509-4547-b9da-678762bd1045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ConvNextFlacDataset(\n",
    "    csv_path=\"/root/autodl-fs/ASVspoof2019.LA.cm.train.trn.txt\",\n",
    "    audio_dir=\"/root/autodl-fs/ASVspoof2019_LA_train/flac\",\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=simple_collate_fn)\n",
    "\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    print(batch[\"input_values\"].shape)  # [B, 3, 224, 224]\n",
    "    print(batch[\"labels\"])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06905caa-cf93-41c1-8062-b45ef50a76ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "dev_dataset = ConvNextFlacDataset(\n",
    "    csv_path=\"/root/autodl-fs/ASVspoof2019.LA.cm.dev.trl.txt\",\n",
    "    audio_dir=\"/root/autodl-fs/ASVspoof2019_LA_dev/flac\",\n",
    ")\n",
    "\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=8, shuffle=True, collate_fn=simple_collate_fn)\n",
    "\n",
    "for batch in dev_dataloader:\n",
    "    print(batch[\"input_values\"].shape)  # [B, 3, 224, 224]\n",
    "    print(batch[\"labels\"])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbd4f4-07b3-4521-9ec2-82860ba2db61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = ConvNextFlacDataset(\n",
    "    csv_path=\"/root/autodl-fs/ASVspoof2019.LA.cm.eval.trl.txt\",\n",
    "    audio_dir=\"/root/autodl-tmp/ASVspoof2019_LA_eval/flac\",\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=8, shuffle=True, collate_fn=simple_collate_fn)\n",
    "\n",
    "for batch in eval_dataloader:\n",
    "    print(batch[\"input_values\"].shape)  # [B, 3, 224, 224]\n",
    "    print(batch[\"labels\"])\n",
    "    break\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fed563-8a98-44a8-b56a-febe3710bd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ConvNextForImageClassification were not initialized from the model checkpoint at /root/autodl-tmp/convnext-tiny-224-copy-1/convnext-tiny-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Model Setup, using download path from huggingface\n",
    "model_path = \"...\"\n",
    "\n",
    "model = ConvNextForImageClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "# Imbalance class mitigation techniques 2:\n",
    "# weighted loss\n",
    "# comput weight\n",
    "count_0 = 22800  # spoof\n",
    "count_1 = 2580   # bonafide\n",
    "total = count_0 + count_1\n",
    "\n",
    "# Inverse frequency weights\n",
    "weight_0 = total / count_0   \n",
    "weight_1 = total / count_1  \n",
    "\n",
    "# Convert to tensor\n",
    "class_weights = torch.tensor([weight_0, weight_1], dtype=torch.float).to(device)\n",
    "\n",
    "# Define weighted loss\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1330140-9a54-4072-a152-cf50733da6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_eer(y_true, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    eer_idx = np.nanargmin(np.abs(fnr - fpr))\n",
    "    eer = (fpr[eer_idx] + fnr[eer_idx]) / 2\n",
    "    return eer\n",
    "\n",
    "def train(model, dataloader):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    y_true, y_score, y_pred = [], [], []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        x = batch[\"input_values\"].to(device)\n",
    "        y = batch[\"labels\"].to(device)\n",
    "\n",
    "        out = model(pixel_values=x)\n",
    "        logits = out.logits\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1]  # class 1 (bonafide)\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_score.extend(probs.detach().cpu().numpy())\n",
    "        y_pred.extend(preds.detach().cpu().numpy())\n",
    "\n",
    "    scheduler.step()\n",
    "    acc = correct / total\n",
    "    eer = compute_eer(y_true, y_score)\n",
    "    auc = roc_auc_score(y_true, y_score)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return total_loss / total, acc, eer, auc, f1\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    y_true, y_score, y_pred = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            x = batch[\"input_values\"].to(device)\n",
    "            y = batch[\"labels\"].to(device)\n",
    "\n",
    "            out = model(pixel_values=x)\n",
    "            logits = out.logits\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "            probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_score.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.detach().cpu().numpy())\n",
    "\n",
    "    acc = correct / total\n",
    "    eer = compute_eer(y_true, y_score)\n",
    "    auc = roc_auc_score(y_true, y_score)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return total_loss / total, acc, eer, auc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f91d9-1c43-4928-8b7a-322720504151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convnext.embeddings.patch_embeddings.weight False\n",
      "convnext.embeddings.patch_embeddings.bias False\n",
      "convnext.embeddings.layernorm.weight False\n",
      "convnext.embeddings.layernorm.bias False\n",
      "convnext.encoder.stages.0.layers.0.layer_scale_parameter False\n",
      "convnext.encoder.stages.0.layers.0.dwconv.weight False\n",
      "convnext.encoder.stages.0.layers.0.dwconv.bias False\n",
      "convnext.encoder.stages.0.layers.0.layernorm.weight False\n",
      "convnext.encoder.stages.0.layers.0.layernorm.bias False\n",
      "convnext.encoder.stages.0.layers.0.pwconv1.weight False\n",
      "convnext.encoder.stages.0.layers.0.pwconv1.bias False\n",
      "convnext.encoder.stages.0.layers.0.pwconv2.weight False\n",
      "convnext.encoder.stages.0.layers.0.pwconv2.bias False\n",
      "convnext.encoder.stages.0.layers.1.layer_scale_parameter False\n",
      "convnext.encoder.stages.0.layers.1.dwconv.weight False\n",
      "convnext.encoder.stages.0.layers.1.dwconv.bias False\n",
      "convnext.encoder.stages.0.layers.1.layernorm.weight False\n",
      "convnext.encoder.stages.0.layers.1.layernorm.bias False\n",
      "convnext.encoder.stages.0.layers.1.pwconv1.weight False\n",
      "convnext.encoder.stages.0.layers.1.pwconv1.bias False\n",
      "convnext.encoder.stages.0.layers.1.pwconv2.weight False\n",
      "convnext.encoder.stages.0.layers.1.pwconv2.bias False\n",
      "convnext.encoder.stages.0.layers.2.layer_scale_parameter False\n",
      "convnext.encoder.stages.0.layers.2.dwconv.weight False\n",
      "convnext.encoder.stages.0.layers.2.dwconv.bias False\n",
      "convnext.encoder.stages.0.layers.2.layernorm.weight False\n",
      "convnext.encoder.stages.0.layers.2.layernorm.bias False\n",
      "convnext.encoder.stages.0.layers.2.pwconv1.weight False\n",
      "convnext.encoder.stages.0.layers.2.pwconv1.bias False\n",
      "convnext.encoder.stages.0.layers.2.pwconv2.weight False\n",
      "convnext.encoder.stages.0.layers.2.pwconv2.bias False\n",
      "convnext.encoder.stages.1.downsampling_layer.0.weight False\n",
      "convnext.encoder.stages.1.downsampling_layer.0.bias False\n",
      "convnext.encoder.stages.1.downsampling_layer.1.weight False\n",
      "convnext.encoder.stages.1.downsampling_layer.1.bias False\n",
      "convnext.encoder.stages.1.layers.0.layer_scale_parameter False\n",
      "convnext.encoder.stages.1.layers.0.dwconv.weight False\n",
      "convnext.encoder.stages.1.layers.0.dwconv.bias False\n",
      "convnext.encoder.stages.1.layers.0.layernorm.weight False\n",
      "convnext.encoder.stages.1.layers.0.layernorm.bias False\n",
      "convnext.encoder.stages.1.layers.0.pwconv1.weight False\n",
      "convnext.encoder.stages.1.layers.0.pwconv1.bias False\n",
      "convnext.encoder.stages.1.layers.0.pwconv2.weight False\n",
      "convnext.encoder.stages.1.layers.0.pwconv2.bias False\n",
      "convnext.encoder.stages.1.layers.1.layer_scale_parameter False\n",
      "convnext.encoder.stages.1.layers.1.dwconv.weight False\n",
      "convnext.encoder.stages.1.layers.1.dwconv.bias False\n",
      "convnext.encoder.stages.1.layers.1.layernorm.weight False\n",
      "convnext.encoder.stages.1.layers.1.layernorm.bias False\n",
      "convnext.encoder.stages.1.layers.1.pwconv1.weight False\n",
      "convnext.encoder.stages.1.layers.1.pwconv1.bias False\n",
      "convnext.encoder.stages.1.layers.1.pwconv2.weight False\n",
      "convnext.encoder.stages.1.layers.1.pwconv2.bias False\n",
      "convnext.encoder.stages.1.layers.2.layer_scale_parameter False\n",
      "convnext.encoder.stages.1.layers.2.dwconv.weight False\n",
      "convnext.encoder.stages.1.layers.2.dwconv.bias False\n",
      "convnext.encoder.stages.1.layers.2.layernorm.weight False\n",
      "convnext.encoder.stages.1.layers.2.layernorm.bias False\n",
      "convnext.encoder.stages.1.layers.2.pwconv1.weight False\n",
      "convnext.encoder.stages.1.layers.2.pwconv1.bias False\n",
      "convnext.encoder.stages.1.layers.2.pwconv2.weight False\n",
      "convnext.encoder.stages.1.layers.2.pwconv2.bias False\n",
      "convnext.encoder.stages.2.downsampling_layer.0.weight False\n",
      "convnext.encoder.stages.2.downsampling_layer.0.bias False\n",
      "convnext.encoder.stages.2.downsampling_layer.1.weight False\n",
      "convnext.encoder.stages.2.downsampling_layer.1.bias False\n",
      "convnext.encoder.stages.2.layers.0.layer_scale_parameter False\n",
      "convnext.encoder.stages.2.layers.0.dwconv.weight False\n",
      "convnext.encoder.stages.2.layers.0.dwconv.bias False\n",
      "convnext.encoder.stages.2.layers.0.layernorm.weight False\n",
      "convnext.encoder.stages.2.layers.0.layernorm.bias False\n",
      "convnext.encoder.stages.2.layers.0.pwconv1.weight False\n",
      "convnext.encoder.stages.2.layers.0.pwconv1.bias False\n",
      "convnext.encoder.stages.2.layers.0.pwconv2.weight False\n",
      "convnext.encoder.stages.2.layers.0.pwconv2.bias False\n",
      "convnext.encoder.stages.2.layers.1.layer_scale_parameter False\n",
      "convnext.encoder.stages.2.layers.1.dwconv.weight False\n",
      "convnext.encoder.stages.2.layers.1.dwconv.bias False\n",
      "convnext.encoder.stages.2.layers.1.layernorm.weight False\n",
      "convnext.encoder.stages.2.layers.1.layernorm.bias False\n",
      "convnext.encoder.stages.2.layers.1.pwconv1.weight False\n",
      "convnext.encoder.stages.2.layers.1.pwconv1.bias False\n",
      "convnext.encoder.stages.2.layers.1.pwconv2.weight False\n",
      "convnext.encoder.stages.2.layers.1.pwconv2.bias False\n",
      "convnext.encoder.stages.2.layers.2.layer_scale_parameter False\n",
      "convnext.encoder.stages.2.layers.2.dwconv.weight False\n",
      "convnext.encoder.stages.2.layers.2.dwconv.bias False\n",
      "convnext.encoder.stages.2.layers.2.layernorm.weight False\n",
      "convnext.encoder.stages.2.layers.2.layernorm.bias False\n",
      "convnext.encoder.stages.2.layers.2.pwconv1.weight False\n",
      "convnext.encoder.stages.2.layers.2.pwconv1.bias False\n",
      "convnext.encoder.stages.2.layers.2.pwconv2.weight False\n",
      "convnext.encoder.stages.2.layers.2.pwconv2.bias False\n",
      "convnext.encoder.stages.2.layers.3.layer_scale_parameter False\n",
      "convnext.encoder.stages.2.layers.3.dwconv.weight False\n",
      "convnext.encoder.stages.2.layers.3.dwconv.bias False\n",
      "convnext.encoder.stages.2.layers.3.layernorm.weight False\n",
      "convnext.encoder.stages.2.layers.3.layernorm.bias False\n",
      "convnext.encoder.stages.2.layers.3.pwconv1.weight False\n",
      "convnext.encoder.stages.2.layers.3.pwconv1.bias False\n",
      "convnext.encoder.stages.2.layers.3.pwconv2.weight False\n",
      "convnext.encoder.stages.2.layers.3.pwconv2.bias False\n",
      "convnext.encoder.stages.2.layers.4.layer_scale_parameter False\n",
      "convnext.encoder.stages.2.layers.4.dwconv.weight False\n",
      "convnext.encoder.stages.2.layers.4.dwconv.bias False\n",
      "convnext.encoder.stages.2.layers.4.layernorm.weight False\n",
      "convnext.encoder.stages.2.layers.4.layernorm.bias False\n",
      "convnext.encoder.stages.2.layers.4.pwconv1.weight False\n",
      "convnext.encoder.stages.2.layers.4.pwconv1.bias False\n",
      "convnext.encoder.stages.2.layers.4.pwconv2.weight False\n",
      "convnext.encoder.stages.2.layers.4.pwconv2.bias False\n",
      "convnext.encoder.stages.2.layers.5.layer_scale_parameter False\n",
      "convnext.encoder.stages.2.layers.5.dwconv.weight False\n",
      "convnext.encoder.stages.2.layers.5.dwconv.bias False\n",
      "convnext.encoder.stages.2.layers.5.layernorm.weight False\n",
      "convnext.encoder.stages.2.layers.5.layernorm.bias False\n",
      "convnext.encoder.stages.2.layers.5.pwconv1.weight False\n",
      "convnext.encoder.stages.2.layers.5.pwconv1.bias False\n",
      "convnext.encoder.stages.2.layers.5.pwconv2.weight False\n",
      "convnext.encoder.stages.2.layers.5.pwconv2.bias False\n",
      "convnext.encoder.stages.2.layers.6.layer_scale_parameter False\n",
      "convnext.encoder.stages.2.layers.6.dwconv.weight False\n",
      "convnext.encoder.stages.2.layers.6.dwconv.bias False\n",
      "convnext.encoder.stages.2.layers.6.layernorm.weight False\n",
      "convnext.encoder.stages.2.layers.6.layernorm.bias False\n",
      "convnext.encoder.stages.2.layers.6.pwconv1.weight False\n",
      "convnext.encoder.stages.2.layers.6.pwconv1.bias False\n",
      "convnext.encoder.stages.2.layers.6.pwconv2.weight False\n",
      "convnext.encoder.stages.2.layers.6.pwconv2.bias False\n",
      "convnext.encoder.stages.2.layers.7.layer_scale_parameter False\n",
      "convnext.encoder.stages.2.layers.7.dwconv.weight False\n",
      "convnext.encoder.stages.2.layers.7.dwconv.bias False\n",
      "convnext.encoder.stages.2.layers.7.layernorm.weight False\n",
      "convnext.encoder.stages.2.layers.7.layernorm.bias False\n",
      "convnext.encoder.stages.2.layers.7.pwconv1.weight False\n",
      "convnext.encoder.stages.2.layers.7.pwconv1.bias False\n",
      "convnext.encoder.stages.2.layers.7.pwconv2.weight False\n",
      "convnext.encoder.stages.2.layers.7.pwconv2.bias False\n",
      "convnext.encoder.stages.2.layers.8.layer_scale_parameter False\n",
      "convnext.encoder.stages.2.layers.8.dwconv.weight False\n",
      "convnext.encoder.stages.2.layers.8.dwconv.bias False\n",
      "convnext.encoder.stages.2.layers.8.layernorm.weight False\n",
      "convnext.encoder.stages.2.layers.8.layernorm.bias False\n",
      "convnext.encoder.stages.2.layers.8.pwconv1.weight False\n",
      "convnext.encoder.stages.2.layers.8.pwconv1.bias False\n",
      "convnext.encoder.stages.2.layers.8.pwconv2.weight False\n",
      "convnext.encoder.stages.2.layers.8.pwconv2.bias False\n",
      "convnext.encoder.stages.3.downsampling_layer.0.weight False\n",
      "convnext.encoder.stages.3.downsampling_layer.0.bias False\n",
      "convnext.encoder.stages.3.downsampling_layer.1.weight False\n",
      "convnext.encoder.stages.3.downsampling_layer.1.bias False\n",
      "convnext.encoder.stages.3.layers.0.layer_scale_parameter False\n",
      "convnext.encoder.stages.3.layers.0.dwconv.weight False\n",
      "convnext.encoder.stages.3.layers.0.dwconv.bias False\n",
      "convnext.encoder.stages.3.layers.0.layernorm.weight False\n",
      "convnext.encoder.stages.3.layers.0.layernorm.bias False\n",
      "convnext.encoder.stages.3.layers.0.pwconv1.weight False\n",
      "convnext.encoder.stages.3.layers.0.pwconv1.bias False\n",
      "convnext.encoder.stages.3.layers.0.pwconv2.weight False\n",
      "convnext.encoder.stages.3.layers.0.pwconv2.bias False\n",
      "convnext.encoder.stages.3.layers.1.layer_scale_parameter False\n",
      "convnext.encoder.stages.3.layers.1.dwconv.weight False\n",
      "convnext.encoder.stages.3.layers.1.dwconv.bias False\n",
      "convnext.encoder.stages.3.layers.1.layernorm.weight False\n",
      "convnext.encoder.stages.3.layers.1.layernorm.bias False\n",
      "convnext.encoder.stages.3.layers.1.pwconv1.weight False\n",
      "convnext.encoder.stages.3.layers.1.pwconv1.bias False\n",
      "convnext.encoder.stages.3.layers.1.pwconv2.weight False\n",
      "convnext.encoder.stages.3.layers.1.pwconv2.bias False\n",
      "convnext.encoder.stages.3.layers.2.layer_scale_parameter False\n",
      "convnext.encoder.stages.3.layers.2.dwconv.weight False\n",
      "convnext.encoder.stages.3.layers.2.dwconv.bias False\n",
      "convnext.encoder.stages.3.layers.2.layernorm.weight False\n",
      "convnext.encoder.stages.3.layers.2.layernorm.bias False\n",
      "convnext.encoder.stages.3.layers.2.pwconv1.weight False\n",
      "convnext.encoder.stages.3.layers.2.pwconv1.bias False\n",
      "convnext.encoder.stages.3.layers.2.pwconv2.weight False\n",
      "convnext.encoder.stages.3.layers.2.pwconv2.bias False\n",
      "convnext.layernorm.weight False\n",
      "convnext.layernorm.bias False\n",
      "classifier.weight True\n",
      "classifier.bias True\n"
     ]
    }
   ],
   "source": [
    "# Freeze layers (Linear Probing)\n",
    "\n",
    "for param in model.convnext.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "    \n",
    "# Partial tuning\n",
    "\n",
    "# for i in range(3):\n",
    "#     for param in model.convnext.encoder.stages[i].parameters():\n",
    "#         param.requires_grad = False\n",
    "# for param in model.convnext.encoder.stages[3].parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name, param.requires_grad)\n",
    "\n",
    "# Full tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869ac37-79d6-4d5c-a9fe-17d181173fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc85d108-1395-4856-8749-9ff1c2cac75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [12:16<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.559229 | Train Acc: 0.831954 | Train EER: 0.311973 | Train AUC: 0.768875 | Train F1: 0.257615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [12:06<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.512924 | Dev   Acc: 0.759499 | Dev EER: 0.267644 | Dev AUC: 0.816671 | Dev F1: 0.356350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8905/8905 [29:50<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval  Loss: 0.551374 | Eval   Acc: 0.743041 | Eval EER: 0.309056 | Eval AUC: 0.775571 | Eval F1: 0.321056\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [12:44<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.500607 | Train Acc: 0.791844 | Train EER: 0.265168 | Train AUC: 0.818194 | Train F1: 0.339377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [12:01<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.481604 | Dev   Acc: 0.785824 | Dev EER: 0.246199 | Dev AUC: 0.836466 | Dev F1: 0.379909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8905/8905 [28:33<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval  Loss: 0.516232 | Eval   Acc: 0.783876 | Eval EER: 0.276045 | Eval AUC: 0.809170 | Eval F1: 0.358126\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [12:52<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.480218 | Train Acc: 0.796612 | Train EER: 0.253020 | Train AUC: 0.834658 | Train F1: 0.362559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [12:33<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.473084 | Dev   Acc: 0.786508 | Dev EER: 0.239303 | Dev AUC: 0.844161 | Dev F1: 0.393829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8905/8905 [23:14<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval  Loss: 0.506473 | Eval   Acc: 0.781855 | Eval EER: 0.267418 | Eval AUC: 0.819617 | Eval F1: 0.372223\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc, train_eer, train_auc, train_f1 = train(model, train_dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train EER: {train_eer:.6f} | Train AUC: {train_auc:.6f} | Train F1: {train_f1:.6f}\" )\n",
    "\n",
    "    dev_loss, dev_acc, dev_eer, dev_auc, dev_f1 = evaluate(model, dev_dataloader)\n",
    "    print(f\"Dev   Loss: {dev_loss:.6f} | Dev   Acc: {dev_acc:.6f} | Dev EER: {dev_eer:.6f} | Dev AUC: {dev_auc:.6f} | Dev F1: {dev_f1:.6f}\")\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss, eval_acc, eval_eer, eval_auc, eval_f1 = evaluate(model, eval_dataloader)\n",
    "    print(f\"Eval  Loss: {eval_loss:.6f} | Eval   Acc: {eval_acc:.6f} | Eval EER: {eval_eer:.6f} | Eval AUC: {eval_auc:.6f} | Eval F1: {eval_f1:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fbc6223-6159-4b83-9617-a491053c8f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/3epoches_weights.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = \"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model_path = \"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/3epoches_weights.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(f\"Model parameters saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8fc10c-e79a-4a56-976f-2a3a10a535f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6440a242-94bb-47c9-b5f1-80cf44291d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [11:01<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.463788 | Train Acc: 0.806462 | Train EER: 0.238462 | Train AUC: 0.847271 | Train F1: 0.388903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [12:31<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.457524 | Dev   Acc: 0.801240 | Dev EER: 0.227843 | Dev AUC: 0.856359 | Dev F1: 0.407203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8905/8905 [29:12<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval  Loss: 0.489517 | Eval   Acc: 0.799613 | Eval EER: 0.254226 | Eval AUC: 0.833895 | Eval F1: 0.390868\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [11:41<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.449006 | Train Acc: 0.815288 | Train EER: 0.228270 | Train AUC: 0.861361 | Train F1: 0.414146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [11:52<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.446245 | Dev   Acc: 0.816374 | Dev EER: 0.220218 | Dev AUC: 0.865154 | Dev F1: 0.423407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8905/8905 [30:36<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval  Loss: 0.478241 | Eval   Acc: 0.812317 | Eval EER: 0.247161 | Eval AUC: 0.843168 | Eval F1: 0.406411\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(\"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/3epoches_weights.pth\"))\n",
    "    \n",
    "epochs = 5\n",
    "for epoch in range(3, epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc, train_eer, train_auc, train_f1 = train(model, train_dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train EER: {train_eer:.6f} | Train AUC: {train_auc:.6f} | Train F1: {train_f1:.6f}\" )\n",
    "\n",
    "    dev_loss, dev_acc, dev_eer, dev_auc, dev_f1 = evaluate(model, dev_dataloader)\n",
    "    print(f\"Dev   Loss: {dev_loss:.6f} | Dev   Acc: {dev_acc:.6f} | Dev EER: {dev_eer:.6f} | Dev AUC: {dev_auc:.6f} | Dev F1: {dev_f1:.6f}\")\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss, eval_acc, eval_eer, eval_auc, eval_f1 = evaluate(model, eval_dataloader)\n",
    "    print(f\"Eval  Loss: {eval_loss:.6f} | Eval   Acc: {eval_acc:.6f} | Eval EER: {eval_eer:.6f} | Eval AUC: {eval_auc:.6f} | Eval F1: {eval_f1:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e5b8d-2973-45a0-9eac-51394f0bc292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "818b39bc-e7fa-4740-8f16-ac0c48ba7e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/5epoches_weights.pth\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/5epoches_weights.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(f\"Model parameters saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "948a3c8e-950d-44da-b9f0-13ec58ac02e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [19:07<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.435528 | Train Acc: 0.821552 | Train EER: 0.214755 | Train AUC: 0.872294 | Train F1: 0.431673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [19:14<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.435469 | Dev   Acc: 0.844429 | Dev EER: 0.213827 | Dev AUC: 0.872202 | Dev F1: 0.432702\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_6.pt\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [19:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.422668 | Train Acc: 0.834082 | Train EER: 0.207323 | Train AUC: 0.881354 | Train F1: 0.451478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [19:13<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.428516 | Dev   Acc: 0.825833 | Dev EER: 0.208388 | Dev AUC: 0.877324 | Dev F1: 0.450121\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_7.pt\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [19:07<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.416485 | Train Acc: 0.836091 | Train EER: 0.200369 | Train AUC: 0.888011 | Train F1: 0.466119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [19:51<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.425343 | Dev   Acc: 0.836137 | Dev EER: 0.205580 | Dev AUC: 0.879832 | Dev F1: 0.455239\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_8.pt\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [19:05<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.411190 | Train Acc: 0.837825 | Train EER: 0.195697 | Train AUC: 0.891192 | Train F1: 0.468354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [19:02<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.424683 | Dev   Acc: 0.839961 | Dev EER: 0.203281 | Dev AUC: 0.882058 | Dev F1: 0.460369\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_9.pt\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [19:43<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.409119 | Train Acc: 0.844484 | Train EER: 0.192590 | Train AUC: 0.894699 | Train F1: 0.478117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [19:17<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.422112 | Dev   Acc: 0.822774 | Dev EER: 0.202950 | Dev AUC: 0.882986 | Dev F1: 0.456755\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_10.pt\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/5epoches_weights.pth\"))\n",
    "save_dir = \"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/\"\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(5, epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc, train_eer, train_auc, train_f1 = train(model, train_dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train EER: {train_eer:.6f} | Train AUC: {train_auc:.6f} | Train F1: {train_f1:.6f}\" )\n",
    "\n",
    "    dev_loss, dev_acc, dev_eer, dev_auc, dev_f1 = evaluate(model, dev_dataloader)\n",
    "    print(f\"Dev   Loss: {dev_loss:.6f} | Dev   Acc: {dev_acc:.6f} | Dev EER: {dev_eer:.6f} | Dev AUC: {dev_auc:.6f} | Dev F1: {dev_f1:.6f}\")\n",
    "\n",
    "    \n",
    "    save_path = os.path.join(save_dir, f\"epoch_{epoch+1}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c2dbd7-cf3c-45b6-8bc6-aa504a54999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8905/8905 [45:24<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval  Loss: 0.460901 | Eval   Acc: 0.804526 | Eval EER: 0.228157 | Eval AUC: 0.860473 | Eval F1: 0.427402\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_loss, eval_acc, eval_eer, eval_auc, eval_f1 = evaluate(model, eval_dataloader)\n",
    "print(f\"Eval  Loss: {eval_loss:.6f} | Eval   Acc: {eval_acc:.6f} | Eval EER: {eval_eer:.6f} | Eval AUC: {eval_auc:.6f} | Eval F1: {eval_f1:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4d25a3-037e-4f86-b519-ef10eff2101e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [16:50<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.405295 | Train Acc: 0.841056 | Train EER: 0.191113 | Train AUC: 0.895736 | Train F1: 0.477867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [11:11<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.421628 | Dev   Acc: 0.829134 | Dev EER: 0.201313 | Dev AUC: 0.883985 | Dev F1: 0.461773\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_11.pt\n",
      "\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [03:03<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.402540 | Train Acc: 0.841647 | Train EER: 0.189003 | Train AUC: 0.896759 | Train F1: 0.479337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [03:00<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.421024 | Dev   Acc: 0.835373 | Dev EER: 0.201335 | Dev AUC: 0.884398 | Dev F1: 0.463536\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_12.pt\n",
      "\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [03:03<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.403877 | Train Acc: 0.843105 | Train EER: 0.189113 | Train AUC: 0.897351 | Train F1: 0.481780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [03:01<00:00, 17.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.417773 | Dev   Acc: 0.836983 | Dev EER: 0.201027 | Dev AUC: 0.884810 | Dev F1: 0.464852\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_13.pt\n",
      "\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [03:02<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.401684 | Train Acc: 0.844878 | Train EER: 0.188788 | Train AUC: 0.898008 | Train F1: 0.483672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [03:00<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.417712 | Dev   Acc: 0.836178 | Dev EER: 0.200982 | Dev AUC: 0.884993 | Dev F1: 0.466019\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_14.pt\n",
      "\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [03:04<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.398734 | Train Acc: 0.844011 | Train EER: 0.188550 | Train AUC: 0.898247 | Train F1: 0.482010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [03:00<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.418265 | Dev   Acc: 0.840968 | Dev EER: 0.200517 | Dev AUC: 0.885216 | Dev F1: 0.466297\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_15.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = \"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/\"\n",
    "\n",
    "epochs = 15\n",
    "for epoch in range(10, epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc, train_eer, train_auc, train_f1 = train(model, train_dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train EER: {train_eer:.6f} | Train AUC: {train_auc:.6f} | Train F1: {train_f1:.6f}\" )\n",
    "\n",
    "    dev_loss, dev_acc, dev_eer, dev_auc, dev_f1 = evaluate(model, dev_dataloader)\n",
    "    print(f\"Dev   Loss: {dev_loss:.6f} | Dev   Acc: {dev_acc:.6f} | Dev EER: {dev_eer:.6f} | Dev AUC: {dev_auc:.6f} | Dev F1: {dev_f1:.6f}\")\n",
    "\n",
    "    \n",
    "    save_path = os.path.join(save_dir, f\"epoch_{epoch+1}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f20bc722-7417-4864-b046-de58ab5a35c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [10:20<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.400060 | Train Acc: 0.848700 | Train EER: 0.188353 | Train AUC: 0.898574 | Train F1: 0.487042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [11:47<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.418513 | Dev   Acc: 0.839599 | Dev EER: 0.200517 | Dev AUC: 0.885305 | Dev F1: 0.466604\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_16.pt\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [12:46<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.400780 | Train Acc: 0.847203 | Train EER: 0.187570 | Train AUC: 0.898743 | Train F1: 0.486630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [12:15<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.417386 | Dev   Acc: 0.839036 | Dev EER: 0.200629 | Dev AUC: 0.885408 | Dev F1: 0.466444\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_17.pt\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [12:02<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.400966 | Train Acc: 0.845626 | Train EER: 0.187658 | Train AUC: 0.898851 | Train F1: 0.485692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [12:20<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.417384 | Dev   Acc: 0.838754 | Dev EER: 0.200186 | Dev AUC: 0.885460 | Dev F1: 0.466436\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_18.pt\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [12:36<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.400293 | Train Acc: 0.845114 | Train EER: 0.187918 | Train AUC: 0.898931 | Train F1: 0.485539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [11:51<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.416290 | Dev   Acc: 0.839559 | Dev EER: 0.200141 | Dev AUC: 0.885509 | Dev F1: 0.467112\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_19.pt\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [12:32<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.400223 | Train Acc: 0.845508 | Train EER: 0.187658 | Train AUC: 0.899000 | Train F1: 0.485501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [12:41<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.416095 | Dev   Acc: 0.839237 | Dev EER: 0.200119 | Dev AUC: 0.885536 | Dev F1: 0.466898\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_20.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = \"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/\"\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(15, epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc, train_eer, train_auc, train_f1 = train(model, train_dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train EER: {train_eer:.6f} | Train AUC: {train_auc:.6f} | Train F1: {train_f1:.6f}\" )\n",
    "\n",
    "    dev_loss, dev_acc, dev_eer, dev_auc, dev_f1 = evaluate(model, dev_dataloader)\n",
    "    print(f\"Dev   Loss: {dev_loss:.6f} | Dev   Acc: {dev_acc:.6f} | Dev EER: {dev_eer:.6f} | Dev AUC: {dev_auc:.6f} | Dev F1: {dev_f1:.6f}\")\n",
    "\n",
    "    \n",
    "    save_path = os.path.join(save_dir, f\"epoch_{epoch+1}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22927967-c807-4daf-9521-0c69612c6239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [10:29<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.397843 | Train Acc: 0.847636 | Train EER: 0.187483 | Train AUC: 0.900736 | Train F1: 0.490581\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_21.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [09:19<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.413916 | Dev   Acc: 0.851191 | Dev EER: 0.196250 | Dev AUC: 0.888006 | Dev F1: 0.476568\n",
      "\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [09:33<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.391057 | Train Acc: 0.852522 | Train EER: 0.182529 | Train AUC: 0.904625 | Train F1: 0.501000\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_22.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [09:16<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.408117 | Dev   Acc: 0.841370 | Dev EER: 0.193397 | Dev AUC: 0.890817 | Dev F1: 0.477806\n",
      "\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [07:11<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.382736 | Train Acc: 0.853310 | Train EER: 0.177097 | Train AUC: 0.907754 | Train F1: 0.501807\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_23.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [05:58<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.406806 | Dev   Acc: 0.849058 | Dev EER: 0.192999 | Dev AUC: 0.891611 | Dev F1: 0.483613\n",
      "\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [06:31<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.384174 | Train Acc: 0.853546 | Train EER: 0.177053 | Train AUC: 0.909503 | Train F1: 0.510341\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_24.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [10:47<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.404882 | Dev   Acc: 0.848495 | Dev EER: 0.190834 | Dev AUC: 0.892924 | Dev F1: 0.486634\n",
      "\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [11:42<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.379236 | Train Acc: 0.857132 | Train EER: 0.175207 | Train AUC: 0.911426 | Train F1: 0.515111\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_25.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [09:30<00:00,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.403247 | Dev   Acc: 0.850064 | Dev EER: 0.190369 | Dev AUC: 0.893325 | Dev F1: 0.487832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_20.pt\"))\n",
    "\n",
    "save_dir = \"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/\"\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(20, epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc, train_eer, train_auc, train_f1 = train(model, train_dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train EER: {train_eer:.6f} | Train AUC: {train_auc:.6f} | Train F1: {train_f1:.6f}\" )\n",
    "\n",
    "    save_path = os.path.join(save_dir, f\"epoch_{epoch+1}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    dev_loss, dev_acc, dev_eer, dev_auc, dev_f1 = evaluate(model, dev_dataloader)\n",
    "    print(f\"Dev   Loss: {dev_loss:.6f} | Dev   Acc: {dev_acc:.6f} | Dev EER: {dev_eer:.6f} | Dev AUC: {dev_auc:.6f} | Dev F1: {dev_f1:.6f}\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d29dac-fde8-44a7-a664-a4d110daff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8905/8905 [26:23<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval  Loss: 0.442991 | Eval   Acc: 0.827590 | Eval EER: 0.217663 | Eval AUC: 0.869955 | Eval F1: 0.451354\n"
     ]
    }
   ],
   "source": [
    "eval_loss, eval_acc, eval_eer, eval_auc, eval_f1 = evaluate(model, eval_dataloader)\n",
    "print(f\"Eval  Loss: {eval_loss:.6f} | Eval   Acc: {eval_acc:.6f} | Eval EER: {eval_eer:.6f} | Eval AUC: {eval_auc:.6f} | Eval F1: {eval_f1:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efaec778-0438-4ba4-8aa6-7d986aa24e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [14:50<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.379757 | Train Acc: 0.858629 | Train EER: 0.172838 | Train AUC: 0.912022 | Train F1: 0.517223\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_26.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [15:37<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.401606 | Dev   Acc: 0.853083 | Dev EER: 0.189618 | Dev AUC: 0.893789 | Dev F1: 0.488509\n",
      "\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [15:10<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.376402 | Train Acc: 0.860205 | Train EER: 0.173554 | Train AUC: 0.912596 | Train F1: 0.520151\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_27.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [13:28<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.401918 | Dev   Acc: 0.846925 | Dev EER: 0.189287 | Dev AUC: 0.893939 | Dev F1: 0.486982\n",
      "\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [14:54<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.376760 | Train Acc: 0.857683 | Train EER: 0.172490 | Train AUC: 0.912815 | Train F1: 0.519169\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_28.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [13:24<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.401534 | Dev   Acc: 0.845838 | Dev EER: 0.189265 | Dev AUC: 0.894088 | Dev F1: 0.485768\n",
      "\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [10:31<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.374960 | Train Acc: 0.857053 | Train EER: 0.172055 | Train AUC: 0.913203 | Train F1: 0.520106\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_29.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [11:16<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.404424 | Dev   Acc: 0.850990 | Dev EER: 0.189551 | Dev AUC: 0.894222 | Dev F1: 0.489520\n",
      "\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [10:37<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.376998 | Train Acc: 0.858392 | Train EER: 0.171317 | Train AUC: 0.913344 | Train F1: 0.519776\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_30.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [10:21<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.401675 | Dev   Acc: 0.851956 | Dev EER: 0.189640 | Dev AUC: 0.894372 | Dev F1: 0.490441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8905/8905 [25:51<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval  Loss: 0.438036 | Eval   Acc: 0.829162 | Eval EER: 0.216318 | Eval AUC: 0.871094 | Eval F1: 0.453917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = \"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/\"\n",
    "\n",
    "epochs = 30\n",
    "for epoch in range(25, epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc, train_eer, train_auc, train_f1 = train(model, train_dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train EER: {train_eer:.6f} | Train AUC: {train_auc:.6f} | Train F1: {train_f1:.6f}\" )\n",
    "\n",
    "    save_path = os.path.join(save_dir, f\"epoch_{epoch+1}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    dev_loss, dev_acc, dev_eer, dev_auc, dev_f1 = evaluate(model, dev_dataloader)\n",
    "    print(f\"Dev   Loss: {dev_loss:.6f} | Dev   Acc: {dev_acc:.6f} | Dev EER: {dev_eer:.6f} | Dev AUC: {dev_auc:.6f} | Dev F1: {dev_f1:.6f}\")\n",
    "\n",
    "eval_loss, eval_acc, eval_eer, eval_auc, eval_f1 = evaluate(model, eval_dataloader)\n",
    "print(f\"Eval  Loss: {eval_loss:.6f} | Eval   Acc: {eval_acc:.6f} | Eval EER: {eval_eer:.6f} | Eval AUC: {eval_auc:.6f} | Eval F1: {eval_f1:.6f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "243f4770-81bd-4e50-a58d-76c653997eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [10:44<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.375912 | Train Acc: 0.859614 | Train EER: 0.169862 | Train AUC: 0.914046 | Train F1: 0.523089\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_31.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [11:58<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.397271 | Dev   Acc: 0.846080 | Dev EER: 0.187672 | Dev AUC: 0.895804 | Dev F1: 0.488360\n",
      "\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [09:23<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.370391 | Train Acc: 0.862648 | Train EER: 0.166754 | Train AUC: 0.916428 | Train F1: 0.528154\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_32.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [09:46<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.396981 | Dev   Acc: 0.856344 | Dev EER: 0.185239 | Dev AUC: 0.897186 | Dev F1: 0.497395\n",
      "\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [10:10<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.366445 | Train Acc: 0.866864 | Train EER: 0.164320 | Train AUC: 0.918540 | Train F1: 0.534765\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_33.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [09:58<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.395811 | Dev   Acc: 0.849259 | Dev EER: 0.184555 | Dev AUC: 0.897660 | Dev F1: 0.494261\n",
      "\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [10:11<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.365496 | Train Acc: 0.865012 | Train EER: 0.162887 | Train AUC: 0.919774 | Train F1: 0.537901\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_34.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [10:02<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.394527 | Dev   Acc: 0.845395 | Dev EER: 0.184157 | Dev AUC: 0.898272 | Dev F1: 0.494406\n",
      "\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [10:06<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.362098 | Train Acc: 0.865209 | Train EER: 0.161841 | Train AUC: 0.920594 | Train F1: 0.538015\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_35.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [09:56<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.393312 | Dev   Acc: 0.856102 | Dev EER: 0.184421 | Dev AUC: 0.898738 | Dev F1: 0.499930\n",
      "\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [10:12<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.361903 | Train Acc: 0.868006 | Train EER: 0.160649 | Train AUC: 0.921023 | Train F1: 0.542475\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_36.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [10:04<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.394210 | Dev   Acc: 0.855539 | Dev EER: 0.183249 | Dev AUC: 0.899184 | Dev F1: 0.500765\n",
      "\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [09:21<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.360675 | Train Acc: 0.868834 | Train EER: 0.161300 | Train AUC: 0.921509 | Train F1: 0.541144\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_37.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [09:06<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.393156 | Dev   Acc: 0.855700 | Dev EER: 0.183204 | Dev AUC: 0.899343 | Dev F1: 0.501321\n",
      "\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [09:26<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.361249 | Train Acc: 0.867376 | Train EER: 0.159344 | Train AUC: 0.921831 | Train F1: 0.540415\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_38.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [09:08<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.392783 | Dev   Acc: 0.857632 | Dev EER: 0.183383 | Dev AUC: 0.899485 | Dev F1: 0.503161\n",
      "\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [11:48<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.359109 | Train Acc: 0.868991 | Train EER: 0.160017 | Train AUC: 0.922085 | Train F1: 0.543457\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_39.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [10:33<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.389688 | Dev   Acc: 0.856505 | Dev EER: 0.183204 | Dev AUC: 0.899551 | Dev F1: 0.501886\n",
      "\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [10:01<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.359059 | Train Acc: 0.869346 | Train EER: 0.159670 | Train AUC: 0.922214 | Train F1: 0.543376\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_40.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [12:33<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.392337 | Dev   Acc: 0.856867 | Dev EER: 0.183271 | Dev AUC: 0.899605 | Dev F1: 0.502240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8905/8905 [26:50<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval  Loss: 0.431238 | Eval   Acc: 0.829302 | Eval EER: 0.210744 | Eval AUC: 0.876300 | Eval F1: 0.461470\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = \"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/\"\n",
    "model.load_state_dict(torch.load(\"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_30.pt\"))\n",
    "\n",
    "epochs = 40\n",
    "for epoch in range(30, epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc, train_eer, train_auc, train_f1 = train(model, train_dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train EER: {train_eer:.6f} | Train AUC: {train_auc:.6f} | Train F1: {train_f1:.6f}\" )\n",
    "\n",
    "    save_path = os.path.join(save_dir, f\"epoch_{epoch+1}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    dev_loss, dev_acc, dev_eer, dev_auc, dev_f1 = evaluate(model, dev_dataloader)\n",
    "    print(f\"Dev   Loss: {dev_loss:.6f} | Dev   Acc: {dev_acc:.6f} | Dev EER: {dev_eer:.6f} | Dev AUC: {dev_auc:.6f} | Dev F1: {dev_f1:.6f}\")\n",
    "\n",
    "eval_loss, eval_acc, eval_eer, eval_auc, eval_f1 = evaluate(model, eval_dataloader)\n",
    "print(f\"Eval  Loss: {eval_loss:.6f} | Eval   Acc: {eval_acc:.6f} | Eval EER: {eval_eer:.6f} | Eval AUC: {eval_auc:.6f} | Eval F1: {eval_f1:.6f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f797bbd-7e42-414f-8464-0a3af03fd4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [08:00<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.359050 | Train Acc: 0.868558 | Train EER: 0.159670 | Train AUC: 0.922349 | Train F1: 0.544013\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_41.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [05:52<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.392145 | Dev   Acc: 0.856585 | Dev EER: 0.183226 | Dev AUC: 0.899646 | Dev F1: 0.502166\n",
      "\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [06:00<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.358065 | Train Acc: 0.868597 | Train EER: 0.158606 | Train AUC: 0.922389 | Train F1: 0.544087\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_42.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [05:53<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.393841 | Dev   Acc: 0.857913 | Dev EER: 0.183406 | Dev AUC: 0.899664 | Dev F1: 0.503516\n",
      "\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [06:02<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.359993 | Train Acc: 0.869110 | Train EER: 0.159300 | Train AUC: 0.922421 | Train F1: 0.544182\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_43.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [05:51<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.391744 | Dev   Acc: 0.858155 | Dev EER: 0.183316 | Dev AUC: 0.899691 | Dev F1: 0.503941\n",
      "\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [06:00<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.359030 | Train Acc: 0.868834 | Train EER: 0.158975 | Train AUC: 0.922457 | Train F1: 0.544285\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_44.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [05:56<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.394683 | Dev   Acc: 0.857994 | Dev EER: 0.183339 | Dev AUC: 0.899709 | Dev F1: 0.503658\n",
      "\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [06:01<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.358210 | Train Acc: 0.869346 | Train EER: 0.159300 | Train AUC: 0.922482 | Train F1: 0.544505\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_45.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [05:55<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.391043 | Dev   Acc: 0.858557 | Dev EER: 0.183361 | Dev AUC: 0.899719 | Dev F1: 0.504233\n",
      "\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [06:00<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.360329 | Train Acc: 0.869307 | Train EER: 0.158975 | Train AUC: 0.922498 | Train F1: 0.544681\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_46.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [05:54<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.392199 | Dev   Acc: 0.857833 | Dev EER: 0.183339 | Dev AUC: 0.899729 | Dev F1: 0.503375\n",
      "\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [06:00<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.359790 | Train Acc: 0.869070 | Train EER: 0.159191 | Train AUC: 0.922510 | Train F1: 0.544857\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_47.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [05:54<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.392903 | Dev   Acc: 0.857793 | Dev EER: 0.183339 | Dev AUC: 0.899734 | Dev F1: 0.503304\n",
      "\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [06:02<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.359380 | Train Acc: 0.869070 | Train EER: 0.159191 | Train AUC: 0.922520 | Train F1: 0.544857\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_48.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [05:54<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.389858 | Dev   Acc: 0.857833 | Dev EER: 0.183339 | Dev AUC: 0.899736 | Dev F1: 0.503514\n",
      "\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [06:03<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.358520 | Train Acc: 0.869031 | Train EER: 0.158953 | Train AUC: 0.922528 | Train F1: 0.544782\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_49.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [05:54<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.392377 | Dev   Acc: 0.857833 | Dev EER: 0.183339 | Dev AUC: 0.899738 | Dev F1: 0.503514\n",
      "\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [05:58<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.358296 | Train Acc: 0.869070 | Train EER: 0.158931 | Train AUC: 0.922530 | Train F1: 0.544857\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_50.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [05:54<00:00,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.393551 | Dev   Acc: 0.857833 | Dev EER: 0.183339 | Dev AUC: 0.899740 | Dev F1: 0.503375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8905/8905 [14:29<00:00, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval  Loss: 0.431750 | Eval   Acc: 0.830229 | Eval EER: 0.210737 | Eval AUC: 0.876351 | Eval F1: 0.462202\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = \"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/\"\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(40, epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc, train_eer, train_auc, train_f1 = train(model, train_dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train EER: {train_eer:.6f} | Train AUC: {train_auc:.6f} | Train F1: {train_f1:.6f}\" )\n",
    "\n",
    "    save_path = os.path.join(save_dir, f\"epoch_{epoch+1}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    dev_loss, dev_acc, dev_eer, dev_auc, dev_f1 = evaluate(model, dev_dataloader)\n",
    "    print(f\"Dev   Loss: {dev_loss:.6f} | Dev   Acc: {dev_acc:.6f} | Dev EER: {dev_eer:.6f} | Dev AUC: {dev_auc:.6f} | Dev F1: {dev_f1:.6f}\")\n",
    "\n",
    "eval_loss, eval_acc, eval_eer, eval_auc, eval_f1 = evaluate(model, eval_dataloader)\n",
    "print(f\"Eval  Loss: {eval_loss:.6f} | Eval   Acc: {eval_acc:.6f} | Eval EER: {eval_eer:.6f} | Eval AUC: {eval_auc:.6f} | Eval F1: {eval_f1:.6f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "916116bc-c7ad-4980-9022-c2060814686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 51/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [13:55<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.359231 | Train Acc: 0.870449 | Train EER: 0.157933 | Train AUC: 0.922846 | Train F1: 0.546107\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_51.pt\n",
      "\n",
      "Epoch 52/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [09:26<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.352349 | Train Acc: 0.869858 | Train EER: 0.156953 | Train AUC: 0.923757 | Train F1: 0.546976\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_52.pt\n",
      "\n",
      "Epoch 53/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [09:24<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.351741 | Train Acc: 0.873680 | Train EER: 0.155041 | Train AUC: 0.925794 | Train F1: 0.553357\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_53.pt\n",
      "\n",
      "Epoch 54/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [09:23<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.350528 | Train Acc: 0.871277 | Train EER: 0.152694 | Train AUC: 0.926578 | Train F1: 0.553871\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_54.pt\n",
      "\n",
      "Epoch 55/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [08:05<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.348563 | Train Acc: 0.873286 | Train EER: 0.152237 | Train AUC: 0.927222 | Train F1: 0.556903\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_55.pt\n",
      "\n",
      "Epoch 56/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [09:25<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.349409 | Train Acc: 0.873010 | Train EER: 0.153323 | Train AUC: 0.927464 | Train F1: 0.556244\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_56.pt\n",
      "\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [11:00<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.346722 | Train Acc: 0.875532 | Train EER: 0.151565 | Train AUC: 0.927773 | Train F1: 0.560089\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_57.pt\n",
      "\n",
      "Epoch 58/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [10:12<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.346041 | Train Acc: 0.873207 | Train EER: 0.151477 | Train AUC: 0.927986 | Train F1: 0.558088\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_58.pt\n",
      "\n",
      "Epoch 59/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [11:04<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.346547 | Train Acc: 0.876950 | Train EER: 0.150610 | Train AUC: 0.928158 | Train F1: 0.561315\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_59.pt\n",
      "\n",
      "Epoch 60/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3173/3173 [15:13<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.344827 | Train Acc: 0.876005 | Train EER: 0.150413 | Train AUC: 0.928227 | Train F1: 0.560904\n",
      "Model saved to /root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_60.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3106/3106 [14:22<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev   Loss: 0.385608 | Dev   Acc: 0.864877 | Dev EER: 0.180642 | Dev AUC: 0.903188 | Dev F1: 0.513408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8905/8905 [28:04<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval  Loss: 0.422554 | Eval   Acc: 0.835788 | Eval EER: 0.206754 | Eval AUC: 0.879867 | Eval F1: 0.471110\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = \"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/\"\n",
    "model.load_state_dict(torch.load(\"/root/autodl-fs/convnext_tiny_fine_tuning/lp_trun_wl/epoch_50.pt\"))\n",
    "\n",
    "\n",
    "epochs = 60\n",
    "for epoch in range(50, epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc, train_eer, train_auc, train_f1 = train(model, train_dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train EER: {train_eer:.6f} | Train AUC: {train_auc:.6f} | Train F1: {train_f1:.6f}\" )\n",
    "\n",
    "    save_path = os.path.join(save_dir, f\"epoch_{epoch+1}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "dev_loss, dev_acc, dev_eer, dev_auc, dev_f1 = evaluate(model, dev_dataloader)\n",
    "print(f\"Dev   Loss: {dev_loss:.6f} | Dev   Acc: {dev_acc:.6f} | Dev EER: {dev_eer:.6f} | Dev AUC: {dev_auc:.6f} | Dev F1: {dev_f1:.6f}\")\n",
    "\n",
    "eval_loss, eval_acc, eval_eer, eval_auc, eval_f1 = evaluate(model, eval_dataloader)\n",
    "print(f\"Eval  Loss: {eval_loss:.6f} | Eval   Acc: {eval_acc:.6f} | Eval EER: {eval_eer:.6f} | Eval AUC: {eval_auc:.6f} | Eval F1: {eval_f1:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfea28f-e899-444e-b3ac-843ecd42e50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
